{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMdzWTj8PXh4",
        "outputId": "6d9aa8df-b545-43c4-c134-959951fcef88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.6578, Test Accuracy: 0.7880\n",
            "Epoch 2/5, Loss: 0.6429, Test Accuracy: 0.7760\n",
            "Epoch 3/5, Loss: 0.6305, Test Accuracy: 0.7480\n",
            "Epoch 4/5, Loss: 0.6169, Test Accuracy: 0.7220\n",
            "Epoch 5/5, Loss: 0.6052, Test Accuracy: 0.7120\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------\n",
        "# 0. Install dependencies\n",
        "# -------------------------------\n",
        "!pip install torch scikit-learn pandas\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load NSL-KDD from GitHub\n",
        "# -------------------------------\n",
        "url_train = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain+.txt\"\n",
        "url_test = \"https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest+.txt\"\n",
        "\n",
        "col_names = [\n",
        "    \"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\n",
        "    \"hot\",\"num_failed_logins\",\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\n",
        "    \"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\n",
        "    \"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
        "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
        "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
        "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\",\"difficulty\"\n",
        "]\n",
        "\n",
        "train_df = pd.read_csv(url_train, names=col_names)\n",
        "test_df = pd.read_csv(url_test, names=col_names)\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Preprocess\n",
        "# -------------------------------\n",
        "# Binary labels: normal=0, attack=1\n",
        "train_df['label'] = train_df['label'].apply(lambda x: 0 if x=='normal' else 1)\n",
        "test_df['label'] = test_df['label'].apply(lambda x: 0 if x=='normal' else 1)\n",
        "\n",
        "# Small subset for demo\n",
        "train_df = train_df.sample(n=2000, random_state=42)\n",
        "test_df = test_df.sample(n=500, random_state=42)\n",
        "\n",
        "# Categorical and numerical features\n",
        "cat_features = ['protocol_type', 'service', 'flag']\n",
        "num_features = [c for c in col_names if c not in cat_features + ['label','difficulty']]\n",
        "\n",
        "# -------------------------------\n",
        "# Handle unseen categories by fitting on train + test\n",
        "# -------------------------------\n",
        "cat_encoders = {}\n",
        "for col in cat_features:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(pd.concat([train_df[col], test_df[col]]))\n",
        "    train_df[col] = le.transform(train_df[col])\n",
        "    test_df[col] = le.transform(test_df[col])\n",
        "    cat_encoders[col] = le\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = MinMaxScaler()\n",
        "train_df[num_features] = scaler.fit_transform(train_df[num_features])\n",
        "test_df[num_features] = scaler.transform(test_df[num_features])\n",
        "\n",
        "# Split into arrays\n",
        "X_cat_train = torch.tensor(train_df[cat_features].values, dtype=torch.long)\n",
        "X_cat_test = torch.tensor(test_df[cat_features].values, dtype=torch.long)\n",
        "X_num_train = torch.tensor(train_df[num_features].values, dtype=torch.float32)\n",
        "X_num_test = torch.tensor(test_df[num_features].values, dtype=torch.float32)\n",
        "y_train = torch.tensor(train_df['label'].values, dtype=torch.long)\n",
        "y_test = torch.tensor(test_df['label'].values, dtype=torch.long)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Define Transformer-based model\n",
        "# -------------------------------\n",
        "class IDS_Transformer(nn.Module):\n",
        "    def __init__(self, num_features, cat_dims, embed_dim=16, num_heads=2, num_layers=1, num_classes=2):\n",
        "        super().__init__()\n",
        "        # Categorical embeddings\n",
        "        self.cat_embeddings = nn.ModuleList([nn.Embedding(cat_size, embed_dim) for cat_size in cat_dims])\n",
        "        # Numerical features projection\n",
        "        self.num_proj = nn.Linear(num_features, embed_dim)\n",
        "        # Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=64, dropout=0.1)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        # Classifier\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(embed_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(32, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, X_num, X_cat):\n",
        "        # Embed categorical features\n",
        "        cat_embeds = [emb(X_cat[:, i]) for i, emb in enumerate(self.cat_embeddings)]\n",
        "        cat_embeds = torch.stack(cat_embeds, dim=1)  # [batch, num_cat, embed_dim]\n",
        "        # Project numerical features\n",
        "        num_embed = self.num_proj(X_num).unsqueeze(1)  # [batch, 1, embed_dim]\n",
        "        # Combine tokens\n",
        "        tokens = torch.cat([num_embed, cat_embeds], dim=1)  # [batch, tokens, embed_dim]\n",
        "        # Transformer expects [seq_len, batch, embed_dim]\n",
        "        tokens = tokens.permute(1,0,2)\n",
        "        out = self.transformer(tokens)\n",
        "        # Pooling\n",
        "        pooled = out.mean(dim=0)\n",
        "        return self.fc(pooled)\n",
        "\n",
        "# Instantiate model\n",
        "cat_dims = [len(cat_encoders[col].classes_) for col in cat_features]\n",
        "model = IDS_Transformer(num_features=X_num_train.shape[1], cat_dims=cat_dims)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Training setup\n",
        "# -------------------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "epochs = 5  # small demo\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Training loop\n",
        "# -------------------------------\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_num_train, X_cat_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = torch.argmax(model(X_num_test, X_cat_test), dim=1)\n",
        "        acc = (preds == y_test).float().mean()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, Test Accuracy: {acc.item():.4f}\")\n"
      ]
    }
  ]
}